{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180d5503",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb13733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Demo tools loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"✅ Demo tools loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba7569",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6132908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model 'sentence-transformers/all-MiniLM-L6-v2' is loaded and ready.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the open-source embedding model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "print(f\"✅ Model '{model_name}' is loaded and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12347d83",
   "metadata": {},
   "source": [
    "## **Text-to-Vector**\n",
    "*(Main component of RAG)*\n",
    "\n",
    "Here is a plain English question being converted to numeric vector.\n",
    "\n",
    "**\"Tell me about an accident in Virginia involving a person over 50\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "693823c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Your Question ---\n",
      "'Tell me about an accident in Virginia involving a person under 25'\n",
      "\n",
      "--- Becomes a 'Vector' (a list of numbers) ---\n",
      "[ 5.15307765e-04  9.48634148e-02  5.71960062e-02  3.66800022e-03\n",
      "  3.42094824e-02  6.10682145e-02  4.36363788e-03  6.15937933e-02\n",
      " -8.74364823e-02  9.87631083e-02  1.03256188e-01 -6.08022092e-03\n",
      "  1.06568299e-02 -4.79812063e-02 -1.02137499e-01 -3.21813188e-02\n",
      "  6.50791079e-02  5.76639958e-02 -9.72741991e-02  3.72935534e-02\n",
      " -2.20543128e-02  3.70991975e-02 -4.73101735e-02 -5.49411867e-03\n",
      " -4.12638858e-02  3.22457636e-03 -5.51801063e-02  5.02467863e-02\n",
      " -6.80102967e-03  1.85090005e-02  6.05112873e-02 -4.82903011e-02\n",
      " -8.57970770e-03 -2.54554674e-02 -4.89624143e-02 -8.27616081e-02\n",
      " -5.60990954e-03  8.82488564e-02  1.50658684e-02 -1.08381193e-02\n",
      " -4.80964817e-02 -5.81862964e-02 -5.51176351e-03 -3.48491184e-02\n",
      " -2.23627221e-02  2.71932073e-02 -2.90675890e-02 -8.60272348e-03\n",
      "  6.27174452e-02  1.03139095e-02 -4.09108363e-02 -8.25642888e-03\n",
      " -1.83683112e-02 -4.97240759e-02 -8.76843743e-03 -8.57353434e-02\n",
      " -8.48722756e-02  7.66668320e-02  5.74001810e-03 -6.14121482e-02\n",
      "  3.75176743e-02  1.85193624e-02 -3.69384140e-02  5.08443080e-03\n",
      " -1.24418018e-02 -5.48707321e-02  9.73833129e-02 -6.21340722e-02\n",
      "  1.20885439e-01 -4.05091345e-02  7.75386319e-02  1.04473892e-03\n",
      " -4.32735272e-02 -2.57272795e-02 -1.83726195e-02 -1.40004307e-02\n",
      "  7.36371651e-02  4.80749756e-02  7.42994696e-02 -2.35882774e-02\n",
      " -8.08902159e-02 -3.99674363e-02 -5.06920088e-03  2.63771974e-02\n",
      " -1.23670381e-02 -3.18205729e-02 -4.69531789e-02  1.35276139e-01\n",
      "  4.33542840e-02 -4.47524665e-03 -5.86422235e-02 -5.71031421e-02\n",
      "  4.40491401e-02 -2.93739401e-02  6.03202358e-02  3.38718370e-02\n",
      " -4.73031402e-02 -1.64502133e-02 -1.46859773e-02  1.11113768e-02\n",
      " -1.69567224e-02  9.70515702e-03  4.59010899e-02  6.45256862e-02\n",
      "  7.17012286e-02  3.62049825e-02  4.90866378e-02  1.33881029e-02\n",
      " -1.32442936e-02 -5.44517359e-04  6.99386746e-02  6.91154599e-02\n",
      "  4.71667275e-02 -5.24778292e-02  4.52017561e-02  1.91454571e-02\n",
      " -4.45263982e-02  2.00893059e-02 -5.77519089e-02 -1.01690464e-01\n",
      " -2.19561569e-02 -4.15697182e-03 -9.89700556e-02  9.41245817e-03\n",
      " -1.41726881e-01 -4.63178866e-02  5.29518425e-02 -4.99521586e-33\n",
      "  2.62500681e-02 -8.04886818e-02  8.38591252e-03  8.60722512e-02\n",
      "  9.80828032e-02  1.51934940e-02 -2.29248330e-02 -6.81004077e-02\n",
      " -9.28417873e-03 -7.06787035e-03  5.52970991e-02 -1.13670997e-01\n",
      "  5.98299205e-02 -1.11778632e-01 -2.79886983e-02  6.84249252e-02\n",
      " -2.38486696e-02  1.87885799e-02 -1.42742395e-01 -5.03080850e-03\n",
      "  5.50539792e-03 -2.17344388e-02  1.14953239e-02  2.60040872e-02\n",
      " -1.29985376e-04 -1.20044835e-02 -2.35673692e-02  9.17614903e-03\n",
      "  2.32867934e-02 -1.82588119e-03 -3.62993293e-02  8.95266831e-02\n",
      "  7.52201155e-02 -1.28339641e-02  3.91794145e-02  2.72923112e-02\n",
      " -1.77509487e-02  2.68266406e-02 -4.11347561e-02 -3.47676352e-02\n",
      " -1.89440921e-02 -1.56003621e-03 -3.27315368e-02  6.21410199e-02\n",
      " -4.15931270e-02 -1.61912851e-02  9.49153560e-04 -6.53409883e-02\n",
      "  1.10885231e-02  1.43669853e-02 -8.29313025e-02  5.38860112e-02\n",
      " -5.19924536e-02 -5.43416589e-02 -3.12212296e-02  1.05270445e-01\n",
      "  2.35072728e-02  9.19112414e-02  1.79123003e-02  6.22398145e-02\n",
      "  3.22324038e-02  3.84141840e-02 -6.88940613e-03  2.95400620e-02\n",
      " -3.10543757e-02 -7.55781308e-02 -4.20339592e-03 -3.30005586e-02\n",
      "  2.16566548e-02  3.77468043e-03 -2.49672234e-02  1.14624634e-01\n",
      "  4.74098022e-04 -8.43526870e-02 -1.51097663e-02  4.32600081e-02\n",
      "  2.61603796e-04 -1.15647435e-01 -2.16918718e-02 -3.59390303e-02\n",
      "  3.16525213e-02 -5.34473211e-02  4.11468074e-02 -5.86772338e-03\n",
      " -5.96781401e-03  1.58419274e-03 -9.51449201e-02  1.50146428e-03\n",
      " -5.47276847e-02  2.24915389e-02 -8.34011473e-03 -4.70345505e-02\n",
      " -1.28583247e-02 -6.18671030e-02  1.04356399e-02 -2.08539953e-34\n",
      " -4.72586639e-02 -8.03390983e-03  1.71728134e-02  8.85047950e-03\n",
      "  9.62715745e-02 -8.63169804e-02 -2.39854362e-02  4.49931882e-02\n",
      " -6.60363287e-02 -1.95669308e-02 -7.22074881e-02 -1.72981415e-02\n",
      "  1.47738522e-02  1.24983557e-01  5.17976610e-03  6.58823475e-02\n",
      "  4.03079391e-02  1.17717069e-02 -2.34236829e-02 -4.18670243e-03\n",
      " -4.81626801e-02  2.53391396e-02 -2.63197124e-02  4.67795953e-02\n",
      " -1.81056559e-02  2.58551706e-02 -3.54269296e-02 -4.67790700e-02\n",
      " -1.11569270e-01 -8.46461654e-02  7.82730710e-03  1.49077326e-02\n",
      "  1.64678302e-02  3.10857482e-02 -1.62435118e-02 -2.77890991e-02\n",
      "  3.06804404e-02 -4.47641015e-02 -7.55485967e-02 -9.86622348e-02\n",
      "  9.90682542e-02 -8.13196320e-03  5.31204753e-02  5.07637206e-03\n",
      "  2.22534109e-02 -6.53097406e-02  4.00974378e-02 -9.45498887e-03\n",
      "  5.59875444e-02  7.22474456e-02 -1.72601454e-02  7.04958395e-04\n",
      "  9.52594802e-02  1.29508868e-01  3.83642986e-02 -5.39222881e-02\n",
      "  3.40682492e-02 -1.23587623e-02  8.12448002e-03 -4.57014749e-03\n",
      "  6.77067740e-03  4.21542227e-02 -8.66196305e-02  3.14441584e-02\n",
      "  4.80484180e-02  1.45093200e-03 -1.51962742e-01 -6.88297227e-02\n",
      " -4.38793488e-02 -4.11053412e-02  3.34764831e-02 -4.55780774e-02\n",
      " -6.42714500e-02 -9.75326523e-02 -8.70284159e-03 -3.67786326e-02\n",
      "  5.49219772e-02  2.25040037e-02 -7.17756078e-02 -1.50560489e-04\n",
      "  4.44788896e-02 -2.70064007e-02  4.21784706e-02  2.19010245e-02\n",
      " -3.27319317e-02  1.88067462e-02  1.10091930e-02 -4.81845848e-02\n",
      " -5.68974577e-02  6.58396818e-03 -8.45354199e-02 -8.46283417e-03\n",
      " -1.50124589e-02 -1.39242997e-02 -6.39325157e-02 -1.67387970e-08\n",
      " -7.14128241e-02  9.10981670e-02 -1.15248002e-01  2.15150584e-02\n",
      " -3.94552127e-02 -2.33097486e-02  6.25625998e-02  4.73584011e-02\n",
      " -5.04126493e-03  8.60688165e-02 -5.40864207e-02  1.85449142e-02\n",
      "  9.63427797e-02  4.52771410e-02  4.40211818e-02 -7.80541077e-02\n",
      "  1.26484120e-02  4.61009629e-02 -3.25976200e-02 -1.76350102e-02\n",
      "  3.34328078e-02  2.35473346e-02  5.58445565e-02  1.13041453e-01\n",
      " -3.28896083e-02 -1.64502971e-02  2.07398981e-02  4.83488776e-02\n",
      " -3.85802165e-02 -3.22956331e-02 -7.22701624e-02  3.79076339e-02\n",
      "  4.35439907e-02 -1.85875166e-02 -3.87005471e-02 -1.62484739e-02\n",
      "  3.66793610e-02 -1.63985137e-02  1.17915552e-02 -5.89248352e-02\n",
      "  3.21698114e-02  1.18250772e-02  3.97916436e-02  6.95912987e-02\n",
      "  1.21247068e-01 -9.25752893e-03 -4.37659724e-03 -2.39679776e-02\n",
      "  1.55443477e-03 -9.25459806e-03 -5.52777201e-02  1.47174820e-02\n",
      "  3.63360420e-02  4.62262742e-02 -9.33140609e-03  5.81481308e-02\n",
      "  1.10912183e-02  5.04976399e-02 -6.48963777e-03 -4.44241017e-02\n",
      "  9.26563703e-03  3.11642736e-02  1.05636269e-02  5.97200764e-04]\n",
      "\n",
      "Total length of the vector: 384\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about an accident in Virginia involving a person under 25\"\n",
    "vector = embeddings.embed_query(question)\n",
    "\n",
    "print(\"--- Your Question ---\")\n",
    "print(f\"'{question}'\")\n",
    "\n",
    "print(\"\\n--- Becomes a 'Vector' (a list of numbers) ---\")\n",
    "print(np.array(vector))\n",
    "print(f\"\\nTotal length of the vector: {len(vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d5c82",
   "metadata": {},
   "source": [
    "#### **Now, let's create two other sentences to compare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1edd89bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedded two more sentences to compare.\n"
     ]
    }
   ],
   "source": [
    "text_similar = \"What is the number of accidents in Virginia invovling alcohol under 25?\"\n",
    "text_dissimilar = \"What's the weather or driving conditions like in California?\"\n",
    "\n",
    "vector_similar = embeddings.embed_query(text_similar)\n",
    "vector_dissimilar = embeddings.embed_query(text_dissimilar)\n",
    "\n",
    "\n",
    "print(\"✅ Embedded two more sentences to compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87382253",
   "metadata": {},
   "source": [
    "#### Now, let's use **'cosine similarity'** to see how **\"close\"** they are.\n",
    "\n",
    "#### A score of **1.0** is a perfect match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea1da660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Similarity Results ---\n",
      "Similarity to 'drunk driving': 0.6403\n",
      "Similarity to 'California weather': 0.2646\n"
     ]
    }
   ],
   "source": [
    "# We need to reshape the vectors for the function\n",
    "v_question = np.array(vector).reshape(1, -1)\n",
    "v_similar = np.array(vector_similar).reshape(1, -1)\n",
    "\n",
    "# Using cosine similarity to compare\n",
    "v_dissimilar = np.array(vector_dissimilar).reshape(1, -1)\n",
    "sim_similar = cosine_similarity(v_question, v_similar)[0][0]\n",
    "sim_dissimilar = cosine_similarity(v_question, v_dissimilar)[0][0]\n",
    "\n",
    "\n",
    "print(\"--- Similarity Results ---\")\n",
    "print(f\"Similarity to 'drunk driving': {sim_similar:.4f}\")\n",
    "print(f\"Similarity to 'California weather': {sim_dissimilar:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937c0ff",
   "metadata": {},
   "source": [
    "## **RAG Implementation**\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a07857e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG tools loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "import bs4\n",
    "import sqlalchemy\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "\n",
    "print(\"✅ RAG tools loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b2b31",
   "metadata": {},
   "source": [
    "## **Connecting to FARS Database**\n",
    "#### *(Fatality Analysis Reporting System)*\n",
    "\n",
    "\n",
    "Here the local **SQL databse** is being connected. \n",
    "\n",
    "\n",
    "Running a **SQL query** to joins all three tables *(accident, person, vehicle)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e23b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database...\n",
      "Created 5000 Documents from MySQL.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CONNECT TO YOUR LOCAL MYSQL DATABASE ---\n",
    "db_uri = \"mysql+pymysql://root:NewStrongPass!123@localhost:3306/fars\"\n",
    "engine = sqlalchemy.create_engine(db_uri)\n",
    "\n",
    "# --- 2. FETCH DATA & SERIALIZE ---\n",
    "documents_to_index = []\n",
    "\n",
    "# Helper maps for state names, etc.\n",
    "print(\"Connecting to database...\")\n",
    "with engine.connect() as connection:\n",
    "    # query JOINS your three tables to get rich data for each accident\n",
    "    query = sqlalchemy.text(\"\"\"\n",
    "        SELECT \n",
    "            a.ST_CASE, a.YEAR, a.STATE, a.MONTH, a.PERSONS, a.VE_FORMS,\n",
    "            p.AGE, p.SEX, p.PER_TYP,\n",
    "            v.MAKE, v.MODEL\n",
    "        FROM \n",
    "            accident_master a\n",
    "        LEFT JOIN \n",
    "            person_master p ON a.ST_CASE = p.ST_CASE\n",
    "        LEFT JOIN \n",
    "            vehicle_master v ON a.ST_CASE = v.ST_CASE\n",
    "        LIMIT 5000; \n",
    "    \"\"\")\n",
    "    \n",
    "    result = connection.execute(query)\n",
    "    \n",
    "    for row in result:\n",
    "        \n",
    "        # 1. Create the text snippet (page_content)\n",
    "        content_snippet = (\n",
    "            f\"Accident Case {row.ST_CASE} in {row.YEAR} involved \"\n",
    "            f\"{row.PERSONS} persons and {row.VE_FORMS} vehicles. \"\n",
    "            f\"Details include: Person (Age: {row.AGE}, Sex: {row.SEX}), \"\n",
    "            f\"Vehicle (Make: {row.MAKE}, Model: {row.MODEL}).\"\n",
    "        )\n",
    "        # 2. Create the metadata (for 100% traceability)\n",
    "        metadata = {\n",
    "            \"source_table\": \"accident_master\",\n",
    "            \"ST_CASE\": row.ST_CASE,\n",
    "            \"YEAR\": row.YEAR,\n",
    "        }\n",
    "        \n",
    "        doc = Document(page_content=content_snippet, metadata=metadata)\n",
    "        documents_to_index.append(doc)\n",
    "\n",
    "print(f\"Created {len(documents_to_index)} Documents from MySQL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae53b6",
   "metadata": {},
   "source": [
    "## **Indexing: Creating the Vector Store**\n",
    "\n",
    "This cell is were vectorization happens. This is the **\"R\" (Retrieval)** component.\n",
    "\n",
    "This is our \"vectorizer\"—a specialized tool that reads text and converts its semantic meaning into a list of numbers (a vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1cfe8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUCCESSFULLY LOADED ---\n",
      "Vector store created at './capstone_chroma_db'\n",
      "Total documents indexed: 35000\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize an open-source embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Build and persist the vector store, runs model through 5000 documents \n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents_to_index, \n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./capstone_chroma_db\" # folder where it will be saved\n",
    ")\n",
    "\n",
    "\n",
    "print(\"--- SUCCESSFULLY LOADED ---\")\n",
    "print(f\"Vector store created at './capstone_chroma_db'\")\n",
    "print(f\"Total documents indexed: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a263121",
   "metadata": {},
   "source": [
    "## **Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4d1a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector store from disk...\n",
      "Retriever created.\n",
      "\n",
      "--- Retriever Test ---\n",
      "Found 5 relevant docs for 'Accidents in Virginia'\n",
      "Top result: Accident Case 40208 in 75 involved 4 persons and 2 vehicles. Details include: Person (Age: 22, Sex: 2), Vehicle (Make: 12, Model: 0).\n"
     ]
    }
   ],
   "source": [
    "# Load the persisted vector store from disk\n",
    "print(\"Loading vector store from disk...\")\n",
    "vectordb = Chroma(\n",
    "    persist_directory=\"./capstone_chroma_db\", \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Creating the retriever\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5}) # 'k=5' finds the top 5 snippets\n",
    "\n",
    "print(\"Retriever created.\")\n",
    "\n",
    "# Testing the retriever\n",
    "print(\"\\n--- Retriever Test ---\")\n",
    "test_docs = retriever.invoke(\"Accidents in Virginia\")\n",
    "print(f\"Found {len(test_docs)} relevant docs for 'Accidents in Virginia'\")\n",
    "print(f\"Top result: {test_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aefc59",
   "metadata": {},
   "source": [
    "## **RAG Chain (Prompt, LLM, and Chain)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "03d55df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain created successfully.\n"
     ]
    }
   ],
   "source": [
    "# 1. Get the RAG prompt from the hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 2. Initialize an open-source LLM via Ollama\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "# 3. Create the RAG chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG chain created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b615cc",
   "metadata": {},
   "source": [
    "## **(Ask a Question)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have enough information to answer this question. The provided context does not mention alcohol involvement in any accidents in Virginia."
     ]
    }
   ],
   "source": [
    "question = \"Tell me about an accident in Virginia involving a person under 25\"\n",
    "# question = \"Tell me about an accident in Virginia that involved animals\"\n",
    "\n",
    "# .stream() gives you the answer as it's being generated\n",
    "for chunk in rag_chain.stream(question):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fars_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
